{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in d:\\programdata\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (9.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageCms\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_path = './faces/Train/'\n",
    "test_path = './faces/Test/'\n",
    "# photos_path = './unsplash_photos/'\n",
    "RGB = 'RGB'\n",
    "LAB = 'LAB'\n",
    "train_split = 0.8\n",
    "random_seed = 42\n",
    "resolution = (256, 256)\n",
    "\n",
    "\n",
    "# Converter for Lab colourspace\n",
    "srgb_p = ImageCms.createProfile(\"sRGB\")\n",
    "lab_p  = ImageCms.createProfile(\"LAB\")\n",
    "\n",
    "rgb2lab = ImageCms.buildTransformFromOpenProfiles(srgb_p, lab_p, \"RGB\", \"LAB\")\n",
    "lab2rgb = ImageCms.buildTransformFromOpenProfiles(lab_p, srgb_p, \"LAB\", \"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = []\n",
    "for photo in os.listdir(photos_path):\n",
    "    rgb_photo = Image.open(os.path.join(photos_path, photo)).resize(resolution).convert(RGB)\n",
    "    lab_photo =  ImageCms.applyTransform(rgb_photo, rgb2lab)\n",
    "    lab_array = np.array(lab_photo)\n",
    "    photos.append(lab_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_np = np.array(photos, dtype= float)\n",
    "photos_np /= 255.0\n",
    "\n",
    "split_len = int(len(photos_np) * train_split)\n",
    "\n",
    "photos_train = photos_np[:split_len]\n",
    "photos_val = photos_np[split_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256, 256, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_set_1 = [64, 128, 256]\n",
    "neurons_set_2 = [512, 256, 128]\n",
    "upsampling_neurons = [64, 32]\n",
    "filter_size = (3,3)\n",
    "upsampling_filter_size = (2,2)\n",
    "activation_hidden = 'relu'\n",
    "activation_output = 'tanh'\n",
    "strides = 2\n",
    "\n",
    "epochs = 10\n",
    "steps_per_epoch = 100\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "\n",
    "# Hidden layer set 1\n",
    "for neuron in neurons_set_1:\n",
    "    model.add(Conv2D(neuron, filter_size, activation=activation_hidden, padding='same'))\n",
    "    model.add(Conv2D(neuron, filter_size, activation=activation_hidden, padding='same', strides=strides))\n",
    "    \n",
    "# Hidden layer set 2\n",
    "for neuron in neurons_set_2:\n",
    "    model.add(Conv2D(neuron, filter_size, activation=activation_hidden, padding='same'))\n",
    "\n",
    "# Upsampling Hidden layer\n",
    "for neuron in upsampling_neurons:\n",
    "    model.add(UpSampling2D(upsampling_filter_size))\n",
    "    model.add(Conv2D(neuron, filter_size, activation=activation_hidden, padding='same'))\n",
    "\n",
    "# prepare output layer\n",
    "model.add(Conv2D(2, (3,3), activation=activation_output, padding='same'))\n",
    "model.add(UpSampling2D(upsampling_filter_size))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 163.8719\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 6.2000e-05\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 6.2000e-05\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 6.2000e-05\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 6.2000e-05\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 6.2000e-05\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 6.2000e-05\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 6.2000e-05\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 6.2000e-05\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 6.2000e-050s - loss: 6.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa778ef048>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2, zoom_range=0.2, rotation_range=20, horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 10\n",
    "def batch_generator(batch_size):\n",
    "    for photos_batch in datagen.flow(photos_train, batch_size=batch_size):\n",
    "        X_batch = photos_np[:,:,:,0]\n",
    "        y_batch = photos_np[:,:,:,1:]\n",
    "        y_batch -= 128\n",
    "        y_batch /= 128\n",
    "        yield (X_batch.reshape(X_batch.shape + (1,)), y_batch)\n",
    "\n",
    "# Train model\n",
    "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
    "model.fit_generator(batch_generator(batch_size), callbacks=[tensorboard], epochs=epochs, steps_per_epoch=steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 104ms/step\n",
      "6.200001371325925e-05\n"
     ]
    }
   ],
   "source": [
    "X_val = photos_val[:,:,:,0]\n",
    "X_val = X_val.reshape(X_val.shape + (1,))\n",
    "\n",
    "y_val = photos_val[:,:,:,1:]\n",
    "y_val /= 128\n",
    "\n",
    "print(model.evaluate(X_val, y_val, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set = []\n",
    "for photo in os.listdir(test_path):\n",
    "    rgb_photo = Image.open(os.path.join(test_path, photo)).resize(resolution).convert(RGB)\n",
    "    lab_photo =  ImageCms.applyTransform(rgb_photo, rgb2lab)\n",
    "    lab_array = np.array(lab_photo)\n",
    "    testing_set.append(lab_array)\n",
    "\n",
    "testing_set = np.array(testing_set, dtype = float)\n",
    "testing_set /= 255.0\n",
    "\n",
    "test_photos = testing_set[:,:,:,0]\n",
    "test_photos = test_photos.reshape(test_photos.shape + (1,))\n",
    "\n",
    "output = model.predict(test_photos)\n",
    "output *= 128\n",
    "output += 128\n",
    "output = output.astype(int)\n",
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "output_path = f\"Result/face_{epochs}_{steps_per_epoch}/\"\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "exists = os.path.exists(output_path)\n",
    "if not exists:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(output_path)\n",
    "   print(\"The new directory is created!\")\n",
    "   \n",
    "for i in range(len(output)):\n",
    "    canvas = np.zeros((256, 256, 3))\n",
    "    bw_part = testing_set[i][:,:,0]\n",
    "    bw_part *= 255\n",
    "    bw_part = bw_part.astype(int)\n",
    "    canvas[:,:,0] = bw_part\n",
    "    canvas[:,:,1:] = output[i]\n",
    "    lab_image = Image.fromarray(canvas, mode=\"LAB\")\n",
    "    rgb_image = ImageCms.applyTransform(lab_image, lab2rgb)\n",
    "    rgb_image.save(output_path+f\"output_{i}.jpeg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea69c99751ef4476b6888678be1b3cd0ebf9b48ac8e071fc0acad2b958c71e1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
